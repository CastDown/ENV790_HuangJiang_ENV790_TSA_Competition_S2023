---
title: "First Model"
author: "Kassie Huang & Tony Jiang"
execute:
  echo: false
  output: pdf_document
editor_options: 
  chunk_output_type: console
---

Library necessary packages

```{r}
#| warning: false
#| message: false
library(readxl)
library(tidyverse)
library(lubridate)
library(zoo)
library(here)
library(forecast)
```

load three datasets into R

```{r}
#| warning: false
setwd(here())
load_original <- read_xlsx(path = "./Data/load.xlsx", col_names = TRUE)
humidity_original <- read_xlsx("./Data/relative_humidity.xlsx", col_names = TRUE)
temp_original <- read_xlsx("./Data/temperature.xlsx", col_names = TRUE)

```

Process load dataset

```{r}
# check the dataset, especially types of each column and missing values
summary(load_original) # we have missing values at h2, need to fix this

# using local mean to fill the missing values
load_original[,4] <- na.aggregate(load_original[,4], na.rm = TRUE)

# acquire the number of columns
load_colno <- load_original %>% ncol()

# get the mean of the load of each day 
load_avg <- rowMeans(load_original[, 3:load_colno])

# combine date and the mean vector to get a new data set
load_processed <- load_original[,2] %>% 
  mutate(load_avg) %>% 
  as.data.frame()

# check for missing value again
summary(load_processed)
```

Process the humidity data

```{r}
# check the dataset, especially types of each column and missing values
summary(humidity_original) # no missing values

# acquire the number of columns
humidity_colno <- humidity_original %>% ncol()

# get the hourly mean of the humidity
humidity_hr_avg <- rowMeans(humidity_original[, 3:humidity_colno])

# create a interim dataframe to store hourly means
humidity_interim <- humidity_original$date %>% 
  as.numeric() %>% 
  as.data.frame() %>% 
  mutate(humidity_hr_avg)

#rename columns
colnames(humidity_interim) <- c("date","humidity_hr_avg")

# get the new dataset with daily average of humidity
humidity_day_avg <- humidity_interim %>% 
  aggregate(humidity_hr_avg ~ date, mean) %>% 
  as.data.frame()

# replace a normal date column with the numeric date in the dataset
humidity_day_avg <- humidity_day_avg[,2] %>% 
  as.data.frame() %>% 
  mutate(load_original[,2]) %>% 
  as.data.frame()

colnames(humidity_day_avg) <- c("humidity_day_avg", "date")

# drop useless data 
remove(humidity_interim)

# check for missing value again
summary(humidity_day_avg)
```

Process the temperature data

```{r}
# check the dataset, especially types of each column and missing values
summary(temp_original) # no missing values

# acquire the number of columns
temp_colno <- temp_original %>% ncol()

# get the hourly mean of the humidity
temp_hr_avg <- rowMeans(temp_original[, 3:temp_colno])

# create a interim dataframe to store hourly means
temp_interim <- temp_original$date %>% 
  as.numeric() %>% 
  as.data.frame() %>% 
  mutate(temp_hr_avg)

#rename columns
colnames(temp_interim) <- c("date","humidity_hr_avg")

# get the new dataset with daily average of humidity
temp_day_avg <- temp_interim %>% 
  aggregate(temp_hr_avg ~ date, mean) %>% 
  as.data.frame()

# replace a normal date column with the numeric date in the dataset
temp_day_avg <- temp_day_avg[,2] %>% 
  as.data.frame() %>% 
  mutate(load_original[,2]) %>% 
  as.data.frame()

colnames(temp_day_avg) <- c("humidity_day_avg", "date")

# drop useless data 
remove(temp_interim)

# check for missing value again
summary(temp_day_avg)
```

create a time series with all three data

```{r}

# combine three processed series together 
combined <- cbind(load_processed[,2], humidity_day_avg[,1], temp_day_avg[,1])

# rename columns to make it look nice
colnames(combined) <- c("load", "humidity", "temp")

# create a time series with two frequency, weeks (7) and days (365.25).
# so we can differentiate weekdays from weekends when modeling
ts_combined <- combined %>%
  msts(seasonal.periods = c(7, 365.25), start = c(2005, 1, 1))
```

For the first model, we'll only be using the load data.

```{r}
#create a time series only for the load data
ts_load <- combined[,1] %>%
  msts(seasonal.periods = c(7, 365.25), start = c(2005, 1, 1))

#decompose the data and plot
ts_load %>% mstl() %>%
  autoplot()

#create a subset for training purpose
n_forecast = 365
ts_load_train <- subset(ts_load, end = length(ts_load)-n_forecast)

#create a subset for testing purpose
ts_load_test <- subset(ts_load, start = length(ts_load)-n_forecast + 1)
```

#Model 1: STL+ETS model Fit the model and check accuracy for further comparison

```{r}
#Fit and forecast STL + ETS model to data
ETS_fit <-  stlf(ts_load_train, h=n_forecast)

#Plot foresting results
autoplot(ETS_fit) + ylab("Active Power")

#Plot model + observed data
autoplot(ts_load) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  ylab("Active Power")

#Check accuracy
Model1_scores <- accuracy(ETS_fit$mean,ts_load_test)

```

Produce the output

```{r}
#forecast
Model1_for <- stlf(ts_load,h=n_forecast)

#create the date sequence
date_for <- seq(as.Date("2011-01-01"), length.out = n_forecast, by = "day")

# Create a data frame with date and load columns
Model1_output <- data.frame(date = date_for, load = Model1_for$mean)

# Write the data frame to a CSV file
# write.csv(forecast_result, "./Output/first_model.csv", row.names = FALSE)

```

#Model 1.1: Try including just one seasonal period, i.e., 365.25 \*Comment from Kassie: 1) I tried only 7, and it didn't work very well, so I changed to only try 365.25 2) I followed Luana's code to compare RMSE just for convenience, but we could change to other metrics later

```{r}
#create a time series only for the load data
ts_load_1.1 <- combined[,1] %>%
  msts(seasonal.periods = 365.25, start = c(2005, 1, 1))

#decompose the data and plot
ts_load_1.1 %>% mstl() %>%
  autoplot()

#create a subset for training and testing
ts_load_train_1.1 <- subset(ts_load_1.1, 
                            end = length(ts_load_1.1) - n_forecast
                            )

ts_load_test_1.1 <- subset(ts_load_1.1, 
                           start = length(ts_load_1.1) - n_forecast + 1
                           )

#Fit and forecast STL + ETS model to data
ETS_fit_1.1 <- stlf(ts_load_train_1.1,h=n_forecast)

#Plot foresting results
autoplot(ETS_fit_1.1) + 
  ylab("Active Power")

#Plot model + observed data
autoplot(ts_load_1.1) +
  autolayer(ETS_fit_1.1, series= "STL + ETS (season: only 365)", PI = FALSE) +
  ylab("Active Power")

#Check accuracy
Model1.1_scores <- accuracy(ETS_fit_1.1$mean,ts_load_test_1.1)

#Compare with Model 1
#create data frame
scores <- as.data.frame(
  rbind(Model1_scores, Model1.1_scores)
  )

row.names(scores) <- c("STL+ETS", "STL + ETS (season: only 365)")

print(scores)

#choose model with lowest RMSE
#MAYBE
best_model_index <- which.min(scores[,"RMSE"])

cat("The best model by RMSE is:", row.names(scores[best_model_index,]))      

```

#Model 2: ARIMA + FOURIER terms Fit the model and check accuracy for further comparison

```{r}
#Fit ARIMA model with fourier terms as exogenous regressors
#TBD:if lambda=0 here
ARIMA_Four_model <- auto.arima(ts_load_train, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_load_train, 
                                          K=c(2,12))
                             )

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Four_fit <- forecast(ARIMA_Four_model,
                           xreg=fourier(ts_load_train,
                                        K=c(2,12),
                                        h=365),
                           h=365
                           ) 

#Plot foresting results
autoplot(ARIMA_Four_fit) + ylab("Active Power")

#Plot model + observed data
autoplot(ts_load) +
  autolayer(ARIMA_Four_fit, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Active Power")


#Check accuracy
Model2_scores <- accuracy(ARIMA_Four_fit$mean,ts_load_test)

```

\*Note from Kassie: I asked GPT-4 what does lambda part do, and here's some helpful comment from it: 1) By setting lambda = 0, you are telling the auto.arima() function to use the log-transformed data when fitting the ARIMA model. 2) This can help stabilize the variance and make the model more accurate, especially when dealing with data that has a multiplicative seasonality or an increasing trend. Still, I'm unsure if it would be better for us to include that and if so, what shall be the value. Maybe try later for 2.x models!

Produce the output

```{r}
#forecast (2 steps)
#TBD: update the model with whole data, or still using the fitted model?
Model2 <- auto.arima(ts_load, 
                     seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_load, 
                                          K=c(2,12))
                             )

Model2_for <- forecast(Model2,
                       xreg=fourier(ts_load,
                                    K=c(2,12),
                                    h=365),
                           h=365
                           ) 

Model2_for_test <- forecast(Model2,
                       lambda = Model2$lambda,
                       xreg=fourier(ts_load,
                                    K=c(2,12),
                                    h=365),
                           h=365
                           ) 

#create the date sequence
#date_for <- seq(as.Date("2011-01-01"), length.out = n_forecast, by = "day")

# Create a data frame with date and load columns
Model2_output <- data.frame(date = date_for, load = Model2_for$mean)

# Write the data frame to a CSV file
# write.csv(forecast_result, "./Output/first_model.csv", row.names = FALSE)

```

\*Note from Kassie: I feel it's a bit strange to fit another ARIMA again here... Maybe check with Luana later

Compare all the models so far

```{r}

#Adding to the scores table
scores <- scores %>%
  rbind(Model2_scores)

#change the name and print the table
n_models <- nrow(scores)
row.names(scores) <- c(row.names(scores)[1:(n_models-1)],"ARIMA_FOURIER")
print(scores)

#choose model with lowest RMSE
#MAYBE
best_model_index <- which.min(scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(scores[best_model_index,]))   
```
