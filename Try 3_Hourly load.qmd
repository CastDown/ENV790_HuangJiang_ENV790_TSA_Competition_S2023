---
title: "Try 3: Hourly Load"
author: "Kassie Huang"
execute:
  echo: false
  output: pdf_document
editor_options: 
  chunk_output_type: console
---

## Data preparation and inspection

### Library necessary packages

```{r}
#| warning: false
#| message: false
library(readxl)
library(tidyverse)
library(lubridate)
library(zoo)
library(here)
library(forecast)
library(openxlsx)
library(outliers)
library(DescTools)

```

### load and process load dataset

```{r}
#| warning: false
setwd(here())
load_original <- read_xlsx(path = "./Data/load.xlsx", col_names = TRUE)

# check the dataset, especially types of each column and missing values
summary(load_original) # we have missing values at h2, need to fix this

# using local mean to fill the missing values
load_original[,4] <- na.aggregate(load_original[,4], na.rm = TRUE)

#re-arrange the table to be hourly dataset
load_processed <- load_original %>%
  gather(key = "hour", value = "consumption", h1:h24) %>%
  arrange(date) %>% #rearranging: multi-column to one-column
  mutate(hour_num = as.integer(str_extract(hour, "\\d+")) - 1,
         datetime = date + hours(hour_num)) %>% #formatting the datetime column
  select(datetime, consumption)

# check for missing value again
summary(load_processed)
```

We didn't consider outliers previously, which could be the potential reason for inaccuracy. So let's try it!

### handling the outliers

```{r}
# inspect the original dataset
# ts plot
ggplot(load_processed, aes(x = datetime, y = consumption)) +
  geom_line() +
  labs(x = "Date", y = "Consumption", title = "Hourly Energy Consumption")
# box plot
ggplot(load_processed, aes(x = datetime, y = consumption)) +
  geom_boxplot() +
  labs(x = "Date", y = "Consumption", title = "Hourly Energy Consumption")

# try 1: tsclean() to clear outliers
# cleaning
drop_outlier_1 <- load_processed$consumption %>%
  ts() %>%
  tsclean() %>%
  as.vector()

# synthesizing
clean_load_processed_1 <- load_processed %>%
  mutate(consumption=drop_outlier_1)

#inspect again: time series plot and box plot
ggplot(clean_load_processed_1, aes(x = datetime, y = consumption)) +
  geom_line() +
  labs(x = "Date", y = "Consumption", title = "Hourly Energy Consumption")

ggplot(clean_load_processed_1, aes(x = datetime, y = consumption)) +
  geom_boxplot() +
  labs(x = "Date", y = "Consumption", title = "Hourly Energy Consumption")

#seems that it didn't improve much, but the extremely handful large values were removed

# try 2: Winsorizing (prompt from GPT-4)
# cleaning
drop_outlier_2 <- load_processed$consumption %>%
  as.vector() %>%
  Winsorize(probs = c(0.001, 0.999))

# synthesizing
clean_load_processed_2 <- load_processed %>%
  mutate(consumption=drop_outlier_2)

#inspect again the cleaned dataset: time series plot and box plot
ggplot(clean_load_processed_2, aes(x = datetime, y = consumption)) +
  geom_line() +
  labs(x = "Date", y = "Consumption", title = "Hourly Energy Consumption")

ggplot(clean_load_processed_2, aes(x = datetime, y = consumption)) +
  geom_boxplot() +
  labs(x = "Date", y = "Consumption", title = "Hourly Energy Consumption")

#seems that all the "spikes" are not present anymore
#but not sure if it would be better for this competition
#I'll leave a line here for future determining

load_processed <- clean_load_processed_1
rm(clean_load_processed_1,clean_load_processed_2,drop_outlier_1,drop_outlier_2)

```

### inspect seasonal patterns

```{r}
# previously, we created frequency mainly based on personal judgement
# in this trial, I'll try to inspect the data first to find the pattern

# given the data now contains 52584 obs.
# I'll only use the first 1 month data, which contains ~4 weeks data 
first1month <- load_processed %>%
  filter(datetime >= "2005-01-01"& datetime < "2005-02-01") 

# time series
ggplot(first1month, aes(x = datetime, y = consumption)) +
  geom_line() +
  labs(x = "Date", y = "Consumption", title = "Hourly Energy Consumption")

# ACF and PACF plot
par(mfrow=c(1,2))
Acf(ts(first1month$consumption),main="first month data",lag.max = 24)
Pacf(ts(first1month$consumption),main="first month data",lag.max = 24)

par(mfrow=c(1,2))
Acf(ts(first1month$consumption),main="first month data",lag.max = 24*3)
Pacf(ts(first1month$consumption),main="first month data",lag.max = 24*3)

par(mfrow=c(1,2))
Acf(ts(first1month$consumption),main="first month data",lag.max = 24*7)
Pacf(ts(first1month$consumption),main="first month data",lag.max = 24*7)

# Based on the ACF and PACF plot, the most pronounce seasonality occurs daily
# As shown in the PACF plot, there are almost always negative spikes every 24 hours
```

###create time series 
```{r}
ts_load <- load_processed$consumption %>%
  msts(seasonal.periods = c(24, 365.25*24), start = c(2005, 1, 1,0))

#decompose the data and plot
ts_load %>% mstl() %>%
  autoplot()

#create a subset for training purpose
n_forecast = 365*24
ts_load_train <- subset(ts_load, end = length(ts_load)-n_forecast)

#create a subset for testing purpose
ts_load_test <- subset(ts_load, start = length(ts_load)-n_forecast + 1)
```


##Model fitting and selection

###Model 1: STL+ETS model 

####Fit the model and check accuracy for further comparison

```{r}
#Fit and forecast STL + ETS model to data
ETS_fit <-  stlf(ts_load_train, h=n_forecast)

#Plot foresting results
autoplot(ETS_fit) + ylab("Active Power")

#Plot model + observed data
autoplot(ts_load) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  ylab("Active Power")

#Check accuracy
Model1_scores <- accuracy(ETS_fit$mean,ts_load_test)

```

####Produce the output

```{r}
# Hourly forecast
Model1_for <- stlf(ts_load,h=59*24)

# Convert the hourly forecast to a data frame
Model1_hourly <- data.frame(hour = 1:(59 * 24), forecast = as.vector(Model1_for$mean))

# Calculate the daily mean forecast
Model1_daily <- Model1_hourly %>%
  mutate(day = ceiling(hour / 24)) %>%
  group_by(day) %>%
  summarise(daily_mean = mean(forecast))

rm(Model1_hourly)

#create the date sequence
date_for <- seq(as.Date("2011-01-01"), length.out = 59, by = "day")

# Create a data frame with date and load columns
Model1_output <- data.frame(date = date_for, load = Model1_daily$daily_mean)

# round the number since Kaggle requires only integers
Model1_output$load <- round(Model1_output$load, 0)

# Write the data frame to a csv file
write.csv(Model1_output, "./Output/Try3_model1.csv", row.names = FALSE)
```

####Check accuracy
```{r}
#set up variables to store accuracy (only for the first time)
scores <- data.frame()
model_names <- vector()

#Adding to accuracy summary
scores <- rbind(scores,Model1_scores)
model_names <- c(model_names,"STL+ETS")
row.names(scores) <- model_names
```

####Model 1.1: Try including just one seasonal period, i.e., 365.25

```{r}
#create a time series only for the load data
ts_load_1.1 <- load_processed$consumption %>%
  msts(seasonal.periods = 365.25*24, start = c(2005, 1, 1, 0))

#decompose the data and plot
ts_load_1.1 %>% mstl() %>%
  autoplot()

#create a subset for training and testing
ts_load_train_1.1 <- subset(ts_load_1.1, 
                            end = length(ts_load_1.1) - n_forecast
                            )

ts_load_test_1.1 <- subset(ts_load_1.1, 
                           start = length(ts_load_1.1) - n_forecast + 1
                           )

#Fit and forecast STL + ETS model to data
ETS_fit_1.1 <- stlf(ts_load_train_1.1,h=n_forecast)

#Plot model + observed data
autoplot(ts_load_1.1) +
  autolayer(ETS_fit_1.1, series= "STL + ETS (season: only 365)", PI = FALSE) +
  ylab("Active Power")

#visual inspection could confirm it's not improving model 1, so quit

```

###Model 2: ARIMA + FOURIER terms 
####Fit the model and check accuracy for further comparison

```{r}
#Fit ARIMA model with fourier terms as exogenous regressors
four_terms <- fourier(ts_load_train, K = c(2, 12))

# Check for any issues in the Fourier terms
any(is.na(four_terms))
any(is.nan(four_terms))
any(is.infinite(four_terms))

# Fit the ARIMA model with Fourier terms
ARIMA_Four_model <- auto.arima(ts_load_train,
                               seasonal = FALSE,
                               xreg = four_terms)

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Four_fit <- forecast(ARIMA_Four_model,
                           xreg=fourier(ts_load_train,
                                        K=c(2,12),
                                        h=365*24),
                           h=365
                           ) 

#Plot foresting results
autoplot(ARIMA_Four_fit) + ylab("Active Power")

#Plot model + observed data
autoplot(ts_load) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  autolayer(ARIMA_Four_fit, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Active Power")


#Check accuracy
Model2_scores <- accuracy(ARIMA_Four_fit$mean,ts_load_test) %>%
  as.data.frame()

```

####Produce the output

```{r}
#forecast (2 steps)
Model2 <- auto.arima(ts_load, 
                     seasonal=FALSE,
                             xreg=fourier(ts_load, 
                                          K=c(2,12))
                             )

Model2_for <- forecast(Model2,
                       xreg=fourier(ts_load,
                                    K=c(2,12),
                                    h=59*24),
                           h=59*24
                           ) 

# Convert the hourly forecast to a data frame
Model2_hourly <- data.frame(hour = 1:(59 * 24), forecast = as.vector(Model2_for$mean))

# Calculate the daily mean forecast
Model2_daily <- Model2_hourly %>%
  mutate(day = ceiling(hour / 24)) %>%
  group_by(day) %>%
  summarise(daily_mean = mean(forecast))

rm(Model2_hourly)

#create the date sequence
date_for <- seq(as.Date("2011-01-01"), length.out = 59, by = "day")

# Create a data frame with date and load columns
Model2_output <- data.frame(date = date_for, load = Model2_daily$daily_mean)

# round the number since Kaggle requires only integers
Model2_output$load <- round(Model2_output$load, 0)

# Write the data frame to a csv file
write.csv(Model2_output, "./Output/Try3_model2.csv", row.names = FALSE)
```

####Check accuracy
```{r}
#Adding to accuracy summary
scores <- rbind(scores,Model2_scores)
model_names <- c(model_names,"ARIMA_FOURIER")
row.names(scores) <- model_names
```


###Compare accuracy

```{r}
print(scores)
```
