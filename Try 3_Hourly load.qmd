---
title: "Try 3: Hourly Load"
author: "Kassie Huang"
execute:
  echo: false
  output: pdf_document
editor_options: 
  chunk_output_type: console
---

Library necessary packages

```{r}
#| warning: false
#| message: false
library(readxl)
library(tidyverse)
library(lubridate)
library(zoo)
library(here)
library(forecast)
library(openxlsx)
```

load and process load dataset

```{r}
#| warning: false
setwd(here())
load_original <- read_xlsx(path = "./Data/load.xlsx", col_names = TRUE)

# check the dataset, especially types of each column and missing values
summary(load_original) # we have missing values at h2, need to fix this

# using local mean to fill the missing values
load_original[,4] <- na.aggregate(load_original[,4], na.rm = TRUE)

#re-arrange the table to be hourly dataset
load_processed <- load_original %>%
  gather(key = "hour", value = "consumption", h1:h24) %>%
  arrange(date) %>% #rearranging: multi-column to one-column
  mutate(hour_num = as.integer(str_extract(hour, "\\d+")) - 1,
         datetime = date + hours(hour_num)) %>% #formatting the datetime column
  select(datetime, consumption)

# check for missing value again
summary(load_processed)
```

create a time series 
```{r}

# create a time series with two frequency, weeks (7) and days (365.25).
# so we can differentiate weekdays from weekends when modeling
ts_combined <- combined %>%
  msts(seasonal.periods = c(7, 365.25), start = c(2005, 1, 1))
```

For the first model, we'll only be using the load data.

```{r}
#create a time series only for the load data
ts_load <- combined[,1] %>%
  msts(seasonal.periods = c(7, 365.25), start = c(2005, 1, 1))

#decompose the data and plot
ts_load %>% mstl() %>%
  autoplot()

#create a subset for training purpose
n_forecast = 365
ts_load_train <- subset(ts_load, end = length(ts_load)-n_forecast)

#create a subset for testing purpose
ts_load_test <- subset(ts_load, start = length(ts_load)-n_forecast + 1)
```

#Model 1: STL+ETS model Fit the model and check accuracy for further comparison

```{r}
#Fit and forecast STL + ETS model to data
ETS_fit <-  stlf(ts_load_train, h=n_forecast)

#Plot foresting results
autoplot(ETS_fit) + ylab("Active Power")

#Plot model + observed data
autoplot(ts_load) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  ylab("Active Power")

#Check accuracy
Model1_scores <- accuracy(ETS_fit$mean,ts_load_test)

```

Produce the output

```{r}
#forecast, only from Jan 1 to Feb 28, 2011
Model1_for <- stlf(ts_load,h=59)

#create the date sequence
date_for <- seq(as.Date("2011-01-01"), length.out = 59, by = "day")

# Create a data frame with date and load columns
Model1_output <- data.frame(date = date_for, load = Model1_for$mean)

# round the number since Kaggle requires only integers
Model1_output$load <- round(Model1_output$load, 0)

# Write the data frame to a csv file
write.csv(Model1_output, "./Output/first_model.csv", row.names = FALSE)
```

#Model 1.1: Try including just one seasonal period, i.e., 365.25 \*Comment from Kassie: 1) I tried only 7, and it didn't work very well, so I changed to only try 365.25 2) I followed Luana's code to compare RMSE just for convenience, but we could change to other metrics later

```{r}
#create a time series only for the load data
ts_load_1.1 <- combined[,1] %>%
  msts(seasonal.periods = 365.25, start = c(2005, 1, 1))

#decompose the data and plot
ts_load_1.1 %>% mstl() %>%
  autoplot()

#create a subset for training and testing
ts_load_train_1.1 <- subset(ts_load_1.1, 
                            end = length(ts_load_1.1) - n_forecast
                            )

ts_load_test_1.1 <- subset(ts_load_1.1, 
                           start = length(ts_load_1.1) - n_forecast + 1
                           )

#Fit and forecast STL + ETS model to data
ETS_fit_1.1 <- stlf(ts_load_train_1.1,h=n_forecast)

#Plot foresting results
autoplot(ETS_fit_1.1) + 
  ylab("Active Power")

#Plot model + observed data
autoplot(ts_load_1.1) +
  autolayer(ETS_fit_1.1, series= "STL + ETS (season: only 365)", PI = FALSE) +
  ylab("Active Power")

#Check accuracy
Model1.1_scores <- accuracy(ETS_fit_1.1$mean,ts_load_test_1.1)

#Compare with Model 1
#create data frame
scores <- as.data.frame(
  rbind(Model1_scores, Model1.1_scores)
  )

row.names(scores) <- c("STL+ETS", "STL + ETS (season: only 365)")

print(scores)

#choose model with lowest RMSE
#MAYBE
best_model_index <- which.min(scores[,"RMSE"])

cat("The best model by RMSE is:", row.names(scores[best_model_index,]))      

```

#Model 2: ARIMA + FOURIER terms Fit the model and check accuracy for further comparison

```{r}
#Fit ARIMA model with fourier terms as exogenous regressors
#TBD:if lambda=0 here
ARIMA_Four_model <- auto.arima(ts_load_train, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_load_train, 
                                          K=c(2,12))
                             )

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Four_fit <- forecast(ARIMA_Four_model,
                           xreg=fourier(ts_load_train,
                                        K=c(2,12),
                                        h=365),
                           h=365
                           ) 

#Plot foresting results
autoplot(ARIMA_Four_fit) + ylab("Active Power")

#Plot model + observed data
autoplot(ts_load) +
  autolayer(ARIMA_Four_fit, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Active Power")


#Check accuracy
Model2_scores <- accuracy(ARIMA_Four_fit$mean,ts_load_test)

```

\*Note from Kassie: I asked GPT-4 what does lambda part do, and here's some helpful comment from it: 1) By setting lambda = 0, you are telling the auto.arima() function to use the log-transformed data when fitting the ARIMA model. 2) This can help stabilize the variance and make the model more accurate, especially when dealing with data that has a multiplicative seasonality or an increasing trend. Still, I'm unsure if it would be better for us to include that and if so, what shall be the value. Maybe try later for 2.x models!

Produce the output

```{r}
#forecast (2 steps)
#TBD: update the model with whole data, or still using the fitted model?
Model2 <- auto.arima(ts_load, 
                     seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_load, 
                                          K=c(2,12))
                             )

Model2_for <- forecast(Model2,
                       xreg=fourier(ts_load,
                                    K=c(2,12),
                                    h=365),
                           h=365
                           ) 

Model2_for_test <- forecast(Model2,
                       lambda = Model2$lambda,
                       xreg=fourier(ts_load,
                                    K=c(2,12),
                                    h=365),
                           h=365
                           ) 

#create the date sequence
date_for <- seq(as.Date("2011-01-01"), length.out = n_forecast, by = "day")

# Create a data frame with date and load columns
Model2_output <- data.frame(date = date_for, load = Model2_for$mean)

# Write the data frame to a CSV file
write.csv(forecast_result, "./Output/first_model.csv", row.names = FALSE)

```

\*Note from Kassie: I feel it's a bit strange to fit another ARIMA again here... Maybe check with Luana later

Compare all the models so far

```{r}

#Adding to the scores table
scores <- scores %>%
  rbind(Model2_scores)

#change the name and print the table
n_models <- nrow(scores)
row.names(scores) <- c(row.names(scores)[1:(n_models-1)],"ARIMA_FOURIER")
print(scores)

#choose model with lowest RMSE
#MAYBE
best_model_index <- which.min(scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(scores[best_model_index,]))   
```
